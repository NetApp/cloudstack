/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */

package org.apache.cloudstack.storage.service;

import com.cloud.utils.exception.CloudRuntimeException;
import feign.FeignException;
import org.apache.cloudstack.storage.feign.FeignClientFactory;
import org.apache.cloudstack.storage.feign.client.AggregateFeignClient;
import org.apache.cloudstack.storage.feign.client.JobFeignClient;
import org.apache.cloudstack.storage.feign.client.NetworkFeignClient;
import org.apache.cloudstack.storage.feign.client.SANFeignClient;
import org.apache.cloudstack.storage.feign.client.SvmFeignClient;
import org.apache.cloudstack.storage.feign.client.VolumeFeignClient;
import org.apache.cloudstack.storage.feign.model.Aggregate;
import org.apache.cloudstack.storage.feign.model.IpInterface;
import org.apache.cloudstack.storage.feign.model.IscsiService;
import org.apache.cloudstack.storage.feign.model.Job;
import org.apache.cloudstack.storage.feign.model.Nas;
import org.apache.cloudstack.storage.feign.model.OntapStorage;
import org.apache.cloudstack.storage.feign.model.Svm;
import org.apache.cloudstack.storage.feign.model.Volume;
import org.apache.cloudstack.storage.feign.model.response.JobResponse;
import org.apache.cloudstack.storage.feign.model.response.OntapResponse;
import org.apache.cloudstack.storage.service.model.AccessGroup;
import org.apache.cloudstack.storage.service.model.CloudStackVolume;
import org.apache.cloudstack.storage.service.model.ProtocolType;
import org.apache.cloudstack.storage.utils.Constants;
import org.apache.cloudstack.storage.utils.Utility;
import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;

import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Objects;

/**
 * Storage Strategy represents the communication path for all the ONTAP storage options
 *
 * ONTAP storage operation would vary based on
 *      Supported protocols: NFS3.0, NFS4.1, FC, iSCSI, Nvme/TCP and Nvme/FC
 *      Supported platform:  Unified and Disaggregated
 */
public abstract class StorageStrategy {
    // Replace @Inject Feign clients with FeignClientFactory
    private final FeignClientFactory feignClientFactory;
    private final AggregateFeignClient aggregateFeignClient;
    private final VolumeFeignClient volumeFeignClient;
    private final SvmFeignClient svmFeignClient;
    private final JobFeignClient jobFeignClient;
    private final NetworkFeignClient networkFeignClient;
    private final SANFeignClient sanFeignClient;

    protected OntapStorage storage;

    /**
     * Presents aggregate object for the unified storage, not eligible for disaggregated
     */
    private List<Aggregate> aggregates;

    private static final Logger s_logger = LogManager.getLogger(StorageStrategy.class);

    public StorageStrategy(OntapStorage ontapStorage) {
        storage = ontapStorage;
        String baseURL = Constants.HTTPS + storage.getManagementLIF();
        s_logger.info("Initializing StorageStrategy with base URL: " + baseURL);
        // Initialize FeignClientFactory and create clients
        this.feignClientFactory = new FeignClientFactory();
        this.aggregateFeignClient = feignClientFactory.createClient(AggregateFeignClient.class, baseURL);
        this.volumeFeignClient = feignClientFactory.createClient(VolumeFeignClient.class, baseURL);
        this.svmFeignClient = feignClientFactory.createClient(SvmFeignClient.class, baseURL);
        this.jobFeignClient = feignClientFactory.createClient(JobFeignClient.class, baseURL);
        this.networkFeignClient = feignClientFactory.createClient(NetworkFeignClient.class, baseURL);
        this.sanFeignClient = feignClientFactory.createClient(SANFeignClient.class, baseURL);
    }

    // Connect method to validate ONTAP cluster, credentials, protocol, and SVM
    public boolean connect() {
        s_logger.info("Attempting to connect to ONTAP cluster at " + storage.getManagementLIF() + " and validate SVM " +
                storage.getSvmName() + ", protocol " + storage.getProtocol());
        //Get AuthHeader
        String authHeader = Utility.generateAuthHeader(storage.getUsername(), storage.getPassword());
        String svmName = storage.getSvmName();
        try {
            // Call the SVM API to check if the SVM exists
            Svm svm = new Svm();
            s_logger.info("Fetching the SVM details...");
            Map<String, Object> queryParams = Map.of(Constants.NAME, svmName, Constants.FIELDS, Constants.AGGREGATES +
                    Constants.COMMA + Constants.STATE);
            OntapResponse<Svm> svms = svmFeignClient.getSvmResponse(queryParams, authHeader);
            if (svms != null && svms.getRecords() != null && !svms.getRecords().isEmpty()) {
                svm = svms.getRecords().get(0);
            } else {
                s_logger.error("No SVM found on the ONTAP cluster by the name" + svmName + ".");
                return false;
            }

            // Validations
            s_logger.info("Validating SVM state and protocol settings...");
            if (!Objects.equals(svm.getState(), Constants.RUNNING)) {
                s_logger.error("SVM " + svmName + " is not in running state.");
                return false;
            }
            if (Objects.equals(storage.getProtocol(), Constants.NFS) && !svm.getNfsEnabled()) {
                s_logger.error("NFS protocol is not enabled on SVM " + svmName);
                return false;
            } else if (Objects.equals(storage.getProtocol(), Constants.ISCSI) && !svm.getIscsiEnabled()) {
                s_logger.error("iSCSI protocol is not enabled on SVM " + svmName);
                return false;
            }
            // TODO: Implement logic to select appropriate aggregate based on storage requirements
            List<Aggregate> aggrs = svm.getAggregates();
            if (aggrs == null || aggrs.isEmpty()) {
                s_logger.error("No aggregates are assigned to SVM " + svmName);
                return false;
            }
            // Set the aggregates which are according to the storage requirements
            for (Aggregate aggr : aggrs) {
                s_logger.debug("Found aggregate: " + aggr.getName() + " with UUID: " + aggr.getUuid());
                Aggregate aggrResp = aggregateFeignClient.getAggregateByUUID(authHeader, aggr.getUuid());
                if (!Objects.equals(aggrResp.getState(), Aggregate.StateEnum.ONLINE)) {
                    s_logger.warn("Aggregate " + aggr.getName() + " is not in online state. Skipping this aggregate.");
                    continue;
                } else if (aggrResp.getSpace() == null || aggrResp.getAvailableBlockStorageSpace() == null ||
                        aggrResp.getAvailableBlockStorageSpace() <= storage.getSize().doubleValue()) {
                    s_logger.warn("Aggregate " + aggr.getName() + " does not have sufficient available space. Skipping this aggregate.");
                    continue;
                }
                s_logger.info("Selected aggregate: " + aggr.getName() + " for volume operations.");
                this.aggregates = List.of(aggr);
                break;
            }
            if (this.aggregates == null || this.aggregates.isEmpty()) {
                s_logger.error("No suitable aggregates found on SVM " + svmName + " for volume creation.");
                return false;
            }

            this.aggregates = aggrs;
            s_logger.info("Successfully connected to ONTAP cluster and validated ONTAP details provided");
        } catch (Exception e) {
           s_logger.error("Failed to connect to ONTAP cluster: " + e.getMessage(), e);
           return false;
        }
        return true;
    }

    // Common methods like create/delete etc., should be here

    /**
     * Creates ONTAP Flex-Volume
     * Eligible only for Unified ONTAP storage
     * throw exception in case of disaggregated ONTAP storage
     *
     * @param volumeName the name of the volume to create
     * @param size the size of the volume in bytes
     * @return the created Volume object
     */
    public Volume createStorageVolume(String volumeName, Long size) {
        s_logger.info("Creating volume: " + volumeName + " of size: " + size + " bytes");

        String svmName = storage.getSvmName();
        if (aggregates == null || aggregates.isEmpty()) {
            s_logger.error("No aggregates available to create volume on SVM " + svmName);
            throw new CloudRuntimeException("No aggregates available to create volume on SVM " + svmName);
        }
        if (size == null || size <= 0) {
            throw new CloudRuntimeException("Invalid volume size provided: " + size);
        }

        // Get the AuthHeader
        String authHeader = Utility.generateAuthHeader(storage.getUsername(), storage.getPassword());

        // Generate the Create Volume Request
        Volume volumeRequest = new Volume();
        Svm svm = new Svm();
        svm.setName(svmName);
        Nas nas = new Nas();
        nas.setPath(Constants.SLASH + volumeName);

        volumeRequest.setName(volumeName);
        volumeRequest.setSvm(svm);

        // Pick the best aggregate for this specific request (largest available, online, and sufficient space).
        long maxAvailableAggregateSpaceBytes = -1L;
        Aggregate aggrChosen = null;
        for (Aggregate aggr : aggregates) {
            s_logger.debug("Found aggregate: " + aggr.getName() + " with UUID: " + aggr.getUuid());
            Aggregate aggrResp = aggregateFeignClient.getAggregateByUUID(authHeader, aggr.getUuid());

            if (aggrResp == null) {
                s_logger.warn("Aggregate details response is null for aggregate " + aggr.getName() + ". Skipping.");
                continue;
            }

            if (!Objects.equals(aggrResp.getState(), Aggregate.StateEnum.ONLINE)) {
                s_logger.warn("Aggregate " + aggr.getName() + " is not in online state. Skipping this aggregate.");
                continue;
            }

            if (aggrResp.getSpace() == null || aggrResp.getAvailableBlockStorageSpace() == null) {
                s_logger.warn("Aggregate " + aggr.getName() + " does not have space information. Skipping this aggregate.");
                continue;
            }

            final long availableBytes = aggrResp.getAvailableBlockStorageSpace().longValue();
            s_logger.debug("Aggregate " + aggr.getName() + " available bytes=" + availableBytes + ", requested=" + size);

            if (availableBytes <= size) {
                s_logger.warn("Aggregate " + aggr.getName() + " does not have sufficient available space. Required=" +
                        size + " bytes, available=" + availableBytes + " bytes. Skipping this aggregate.");
                continue;
            }

            if (availableBytes > maxAvailableAggregateSpaceBytes) {
                maxAvailableAggregateSpaceBytes = availableBytes;
                aggrChosen = aggr;
            }
        }

        if (aggrChosen == null) {
            s_logger.error("No suitable aggregates found on SVM " + svmName + " for volume creation.");
            throw new CloudRuntimeException("No suitable aggregates found on SVM " + svmName + " for volume operations.");
        }
        s_logger.info("Selected aggregate: " + aggrChosen.getName() + " for volume operations.");

        Aggregate aggr = new Aggregate();
        aggr.setName(aggrChosen.getName());
        aggr.setUuid(aggrChosen.getUuid());
        volumeRequest.setAggregates(List.of(aggr));
        volumeRequest.setSize(size);
        volumeRequest.setNas(nas);
        try {
            JobResponse jobResponse = volumeFeignClient.createVolumeWithJob(authHeader, volumeRequest);
            if (jobResponse == null || jobResponse.getJob() == null) {
                throw new CloudRuntimeException("Failed to initiate volume creation for " + volumeName);
            }
            String jobUUID = jobResponse.getJob().getUuid();

            //Create URI for GET Job API
            Boolean jobSucceeded = jobPollForSuccess(jobUUID);
            if (!jobSucceeded) {
                s_logger.error("Volume creation job failed for volume: " + volumeName);
                throw new CloudRuntimeException("Volume creation job failed for volume: " + volumeName);
            }
            s_logger.info("Volume creation job completed successfully for volume: " + volumeName);
        } catch (Exception e) {
            s_logger.error("Exception while creating volume: ", e);
            throw new CloudRuntimeException("Failed to create volume: " + e.getMessage());
        }
        // Verify if the Volume has been created and set the Volume object
        // Call the VolumeFeignClient to get the created volume details
        OntapResponse<Volume> volumesResponse = volumeFeignClient.getAllVolumes(authHeader, Map.of(Constants.NAME, volumeName));
        if (volumesResponse == null || volumesResponse.getRecords() == null || volumesResponse.getRecords().isEmpty()) {
            s_logger.error("Volume " + volumeName + " not found after creation.");
            throw new CloudRuntimeException("Volume " + volumeName + " not found after creation.");
        }
        Volume createdVolume = volumesResponse.getRecords().get(0);
        if (createdVolume == null) {
            s_logger.error("Failed to retrieve details of the created volume " + volumeName);
            throw new CloudRuntimeException("Failed to retrieve details of the created volume " + volumeName);
        } else if (createdVolume.getName() == null || !createdVolume.getName().equals(volumeName)) {
            s_logger.error("Mismatch in created volume name. Expected: " + volumeName + ", Found: " + createdVolume.getName());
            throw new CloudRuntimeException("Mismatch in created volume name. Expected: " + volumeName + ", Found: " + createdVolume.getName());
        }
        s_logger.info("Volume created successfully: " + volumeName);
        try {
            Map<String, Object> queryParams = Map.of(Constants.NAME, volumeName);
            s_logger.debug("Fetching volume details for: " + volumeName);

            OntapResponse<Volume> ontapVolume = volumeFeignClient.getVolume(authHeader, queryParams);
            s_logger.debug("Feign call completed. Processing response...");

            if (ontapVolume == null) {
                s_logger.error("OntapResponse is null for volume: " + volumeName);
                throw new CloudRuntimeException("Failed to fetch volume " + volumeName + ": Response is null");
            }
            s_logger.debug("OntapResponse is not null. Checking records field...");

            if (ontapVolume.getRecords() == null) {
                s_logger.error("OntapResponse.records is null for volume: " + volumeName);
                throw new CloudRuntimeException("Failed to fetch volume " + volumeName + ": Records list is null");
            }
            s_logger.debug("Records field is not null. Size: " + ontapVolume.getRecords().size());

            if (ontapVolume.getRecords().isEmpty()) {
                s_logger.error("OntapResponse.records is empty for volume: " + volumeName);
                throw new CloudRuntimeException("Failed to fetch volume " + volumeName + ": No records found");
            }

            Volume volume = ontapVolume.getRecords().get(0);
            s_logger.info("Volume retrieved successfully: " + volumeName + ", UUID: " + volume.getUuid());
            return volume;
        } catch (Exception e) {
            s_logger.error("Exception while retrieving volume details for: " + volumeName, e);
            throw new CloudRuntimeException("Failed to fetch volume: " + volumeName + ". Error: " + e.getMessage(), e);
        }
    }

    /**
     * Updates ONTAP Flex-Volume
     * Eligible only for Unified ONTAP storage
     * throw exception in case of disaggregated ONTAP storage
     *
     * @param volume the volume to update
     * @return the updated Volume object
     */
    public Volume updateStorageVolume(Volume volume) {
        //TODO
        return null;
    }

    /**
     * Delete ONTAP Flex-Volume
     * Eligible only for Unified ONTAP storage
     * throw exception in case of disaggregated ONTAP storage
     *
     * @param volume the volume to delete
     */
    public void deleteStorageVolume(Volume volume) {
        s_logger.info("Deleting ONTAP volume by name: " + volume.getName() + " and uuid: " + volume.getUuid());
        // Calling the VolumeFeignClient to delete the volume
        String authHeader = Utility.generateAuthHeader(storage.getUsername(), storage.getPassword());
        try {
            // TODO: Implement lun and file deletion, if any, before deleting the volume
            JobResponse jobResponse = volumeFeignClient.deleteVolume(authHeader, volume.getUuid());
            Boolean jobSucceeded = jobPollForSuccess(jobResponse.getJob().getUuid());
            if (!jobSucceeded) {
                s_logger.error("Volume deletion job failed for volume: " + volume.getName());
                throw new CloudRuntimeException("Volume deletion job failed for volume: " + volume.getName());
            }
            s_logger.info("Volume deleted successfully: " + volume.getName());
        } catch (FeignException.FeignClientException e) {
            s_logger.error("Exception while deleting volume: ", e);
            throw new CloudRuntimeException("Failed to delete volume: " + e.getMessage());
        }
        s_logger.info("ONTAP volume deletion process completed for volume: " + volume.getName());
    }

    /**
     * Gets ONTAP Flex-Volume
     * Eligible only for Unified ONTAP storage
     * throw exception in case of disaggregated ONTAP storage
     *
     * @param volume the volume to retrieve
     * @return the retrieved Volume object
     */
    public Volume getStorageVolume(Volume volume) {
        //TODO
        return null;
    }

    /**
     * Get the storage path based on protocol.
     * For iSCSI: Returns the iSCSI target IQN (e.g., iqn.1992-08.com.netapp:sn.xxx:vs.3)
     * For NFS: Returns the mount path (to be implemented)
     *
     * @return the storage path as a String
     */
    public String getStoragePath() {
        String authHeader = Utility.generateAuthHeader(storage.getUsername(), storage.getPassword());
        String targetIqn = null;
        try {
            if (storage.getProtocol() == ProtocolType.ISCSI) {
                // For iSCSI, fetch the target IQN from the iSCSI service
                s_logger.info("Fetching iSCSI target IQN for SVM: {}", storage.getSvmName());

                Map<String, Object> queryParams = new HashMap<>();
                queryParams.put(Constants.SVM_DOT_NAME, storage.getSvmName());
                queryParams.put("fields", "enabled,target");
                queryParams.put("max_records", "1");

                OntapResponse<IscsiService> response = sanFeignClient.getIscsiServices(authHeader, queryParams);

                if (response == null || response.getRecords() == null || response.getRecords().isEmpty()) {
                    throw new CloudRuntimeException("No iSCSI service found for SVM: " + storage.getSvmName());
                }

                IscsiService iscsiService = response.getRecords().get(0);

                if (iscsiService.getTarget() == null || iscsiService.getTarget().getName() == null) {
                    throw new CloudRuntimeException("iSCSI target IQN not found for SVM: " + storage.getSvmName());
                }

                targetIqn = iscsiService.getTarget().getName();
                s_logger.info("Retrieved iSCSI target IQN: {}", targetIqn);
                return targetIqn;

            } else if (storage.getProtocol() == ProtocolType.NFS3) {
                // TODO: Implement NFS path retrieval logic
            } else {
                throw new CloudRuntimeException("Unsupported protocol for path retrieval: " + storage.getProtocol());
            }

        } catch (FeignException.FeignClientException e) {
            s_logger.error("Exception while retrieving storage path for protocol {}: {}", storage.getProtocol(), e.getMessage(), e);
            throw new CloudRuntimeException("Failed to retrieve storage path: " + e.getMessage());
        }
        return targetIqn;
    }



    /**
     * Get the network ip interface
     *
     * @return the network interface ip as a String
     */

    public String getNetworkInterface() {
        // Feign call to get network interfaces
        String authHeader = Utility.generateAuthHeader(storage.getUsername(), storage.getPassword());
        try {
            Map<String, Object> queryParams = new HashMap<>();
            queryParams.put(Constants.SVM_DOT_NAME, storage.getSvmName());
            if (storage.getProtocol() != null) {
                switch (storage.getProtocol()) {
                    case NFS3:
                        queryParams.put(Constants.SERVICES, Constants.DATA_NFS);
                        break;
                    case ISCSI:
                        queryParams.put(Constants.SERVICES, Constants.DATA_ISCSI);
                        break;
                    default:
                        s_logger.error("Unsupported protocol: " + storage.getProtocol());
                        throw new CloudRuntimeException("Unsupported protocol: " + storage.getProtocol());
                }
            }
            queryParams.put(Constants.FIELDS, Constants.IP_ADDRESS);
            queryParams.put(Constants.RETURN_RECORDS, Constants.TRUE);
            OntapResponse<IpInterface> response =
                    networkFeignClient.getNetworkIpInterfaces(authHeader, queryParams);
            if (response != null && response.getRecords() != null && !response.getRecords().isEmpty()) {
                IpInterface ipInterface = null;
                // For simplicity, return the first interface's name (Of IPv4 type for NFS3)
                if (storage.getProtocol() == ProtocolType.ISCSI) {
                    ipInterface = response.getRecords().get(0);
                } else if (storage.getProtocol() == ProtocolType.NFS3) {
                    for (IpInterface iface : response.getRecords()) {
                        if (iface.getIp().getAddress().contains(".")) {
                            ipInterface = iface;
                            break;
                        }
                    }
                }

                s_logger.info("Retrieved network interface: " + ipInterface.getIp().getAddress());
                return ipInterface.getIp().getAddress();
            } else {
                throw new CloudRuntimeException("No network interfaces found for SVM " + storage.getSvmName() +
                        " for protocol " + storage.getProtocol());
            }
        } catch (FeignException.FeignClientException e) {
            s_logger.error("Exception while retrieving network interfaces: ", e);
            throw new CloudRuntimeException("Failed to retrieve network interfaces: " + e.getMessage());
        }
    }

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses.
     * it is going to mimic
     * createLun       for iSCSI, FC protocols
     * createFile      for NFS3.0 and NFS4.1 protocols
     * createNameSpace for Nvme/TCP and Nvme/FC protocol
     *
     * @param cloudstackVolume the CloudStack volume to create
     * @return the created CloudStackVolume object
     */
    abstract public CloudStackVolume createCloudStackVolume(CloudStackVolume cloudstackVolume);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses.
     * it is going to mimic
     * updateLun       for iSCSI, FC protocols
     * updateFile      for NFS3.0 and NFS4.1 protocols
     * updateNameSpace for Nvme/TCP and Nvme/FC protocol
     *
     * @param cloudstackVolume the CloudStack volume to update
     * @return the updated CloudStackVolume object
     */
    abstract CloudStackVolume updateCloudStackVolume(CloudStackVolume cloudstackVolume);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses.
     * it is going to mimic
     * deleteLun       for iSCSI, FC protocols
     * deleteFile      for NFS3.0 and NFS4.1 protocols
     * deleteNameSpace for Nvme/TCP and Nvme/FC protocol
     *
     * @param cloudstackVolume the CloudStack volume to delete
     */
    abstract public void deleteCloudStackVolume(CloudStackVolume cloudstackVolume);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses.
     * it is going to mimic
     *     cloneLun       for iSCSI, FC protocols
     *     cloneFile      for NFS3.0 and NFS4.1 protocols
     *     cloneNameSpace for Nvme/TCP and Nvme/FC protocol
     * @param cloudstackVolume the CloudStack volume to copy
     */
    abstract public void copyCloudStackVolume(CloudStackVolume cloudstackVolume);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses.
     * it is going to mimic
     *     getLun       for iSCSI, FC protocols
     *     getFile      for NFS3.0 and NFS4.1 protocols
     *     getNameSpace for Nvme/TCP and Nvme/FC protocol
     * @param cloudStackVolumeMap the CloudStack volume to retrieve
     * @return the retrieved CloudStackVolume object
     */
    abstract public CloudStackVolume getCloudStackVolume(Map<String, String> cloudStackVolumeMap);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses
     *     createiGroup       for iSCSI and FC protocols
     *     createExportPolicy for NFS 3.0 and NFS 4.1 protocols
     *     createSubsystem    for Nvme/TCP and Nvme/FC protocols
     * @param accessGroup the access group to create
     * @return the created AccessGroup object
     */
    abstract public AccessGroup createAccessGroup(AccessGroup accessGroup);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses
     *     deleteiGroup       for iSCSI and FC protocols
     *     deleteExportPolicy for NFS 3.0 and NFS 4.1 protocols
     *     deleteSubsystem    for Nvme/TCP and Nvme/FC protocols
     * @param accessGroup the access group to delete
     */
    abstract public void deleteAccessGroup(AccessGroup accessGroup);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses
     *     updateiGroup       example add/remove-Iqn   for iSCSI and FC protocols
     *     updateExportPolicy example add/remove-Rule for NFS 3.0 and NFS 4.1 protocols
     *     //TODO  for Nvme/TCP and Nvme/FC protocols
     * @param accessGroup the access group to update
     * @return the updated AccessGroup object
     */
    abstract AccessGroup updateAccessGroup(AccessGroup accessGroup);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses
     *     e.g., getIGroup for iSCSI and FC protocols
     *     e.g., getExportPolicy for NFS 3.0 and NFS 4.1 protocols
     *     //TODO  for Nvme/TCP and Nvme/FC protocols
      * @param values map to get access group values like name, svm name etc.
     */
    abstract public AccessGroup getAccessGroup(Map<String, String> values);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses
     *     lunMap  for iSCSI and FC protocols
     *     //TODO  for Nvme/TCP and Nvme/FC protocols
     * @param values map including SVM name, LUN name, and igroup name
     * @return map containing logical unit number for the new/existing mapping
     */
    abstract public Map<String,String> enableLogicalAccess(Map<String,String> values);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses
     *     lunUnmap  for iSCSI and FC protocols
     *     //TODO  for Nvme/TCP and Nvme/FC protocols
     * @param values map including LUN UUID and iGroup UUID
     */
    abstract public void disableLogicalAccess(Map<String, String> values);

    /**
     * Method encapsulates the behavior based on the opted protocol in subclasses
     *     lunMap lookup for iSCSI/FC protocols (GET-only, no side-effects)
     *     //TODO  for Nvme/TCP and Nvme/FC protocols
     * @param values map with SVM name, LUN name, and igroup name
     * @return map containing logical unit number if mapping exists; otherwise null
     */
    abstract public Map<String, String> getLogicalAccess(Map<String, String> values);

    private Boolean jobPollForSuccess(String jobUUID) {
        //Create URI for GET Job API
        int jobRetryCount = 0;
        Job jobResp = null;
        try {
            String authHeader = Utility.generateAuthHeader(storage.getUsername(), storage.getPassword());
            while (jobResp == null || !jobResp.getState().equals(Constants.JOB_SUCCESS)) {
                if (jobRetryCount >= Constants.JOB_MAX_RETRIES) {
                    s_logger.error("Job did not complete within expected time.");
                    throw new CloudRuntimeException("Job did not complete within expected time.");
                }

                try {
                    jobResp = jobFeignClient.getJobByUUID(authHeader, jobUUID);
                    if (jobResp == null) {
                        s_logger.warn("Job with UUID " + jobUUID + " not found. Retrying...");
                    } else if (jobResp.getState().equals(Constants.JOB_FAILURE)) {
                        throw new CloudRuntimeException("Job failed with error: " + jobResp.getMessage());
                    }
                } catch (FeignException.FeignClientException e) {
                    throw new CloudRuntimeException("Failed to fetch job status: " + e.getMessage());
                }

                jobRetryCount++;
                Thread.sleep(Constants.CREATE_VOLUME_CHECK_SLEEP_TIME); // Sleep for 2 seconds before polling again
            }
            if (jobResp == null || !jobResp.getState().equals(Constants.JOB_SUCCESS)) {
                return false;
            }
        } catch (FeignException.FeignClientException e) {
            throw new CloudRuntimeException("Failed to fetch job status: " + e.getMessage());
        } catch (InterruptedException e) {
            throw new RuntimeException(e);
        }
        return true;
    }
}
